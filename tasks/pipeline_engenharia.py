from crewai import Task
from utils.file_split_writer import salvar_multiplos_arquivos

def engenharia_pipelines(agent):
    return Task(
        description="""
VocÃª Ã© responsÃ¡vel por construir mÃºltiplos pipelines de ingestÃ£o e transformaÃ§Ã£o para um Data Warehouse baseado em dados da Receita Federal.

ğŸ”¸ Gere os seguintes arquivos:

ğŸŸ£ TransformaÃ§Ãµes (dbt .sql)
- outputs/dbt/dim_empresa.sql
- outputs/dbt/dim_estabelecimento.sql
- outputs/dbt/dim_socio.sql
- outputs/dbt/dim_simples.sql

ğŸŸ¡ Metadados dbt (schema.yml)
- outputs/dbt/schema.yml â†’ Incluindo todos os modelos acima

ğŸ”µ IngestÃ£o via Airbyte (.json)
- outputs/airbyte/source_empresas.json
- outputs/airbyte/source_estabelecimentos.json
- outputs/airbyte/source_socios.json
- outputs/airbyte/source_simples.json

ğŸŸ¢ DAG Airflow
- outputs/airflow/dag_receita_dw.py

ğŸ”¸ FORMATO DE RESPOSTA (obrigatÃ³rio):
Delimite cada arquivo com:
---FILENAME--- outputs/dbt/dim_empresa.sql
<conteÃºdo do arquivo>

---FILENAME--- outputs/dbt/schema.yml
<conteÃºdo do schema.yml>

ğŸ”¸ Linguagem por bloco:
- SQL â†’ `<pre><code class="language-sql">`
- YAML â†’ `language-yaml`
- JSON â†’ `language-json`
- Python â†’ `language-python`

Seja tÃ©cnico, completo e funcional.
""",
        expected_output="MÃºltiplos arquivos para pipelines reais: SQL, YAML, JSON e Python.",
        agent=agent,
        callback=lambda output: salvar_multiplos_arquivos(
            conteudo=getattr(output, "response", str(output)),
            pasta_base="outputs"
        )
    )
